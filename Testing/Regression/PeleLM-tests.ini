[main]
testTopDir     = PELEREGTESTHOME/TestData/PeleLM/
webTopDir      = PELEREGTESTHOME/TestData/PeleLM/web

MAKE = make
sourceTree = C_Src
numMakeJobs = 8

COMP = g++
FCOMP = gfortran
add_to_c_make_command = TEST=TRUE USE_ASSERTION=TRUE

# suiteName is the name prepended to all output directories
suiteName = PeleLM

reportActiveTestsOnly = 1

# Add "GO UP" link at the top of the web page?
goUpLink = 1

# email
sendEmailWhenFail = 0
emailTo = username@domain.com
emailBody = Check PeleRegressionTesting/TestData/PeleC/web on the runner for more details.

# MPIcommand should use the placeholders:
#   @host@ to indicate where to put the hostname to run on
#   @nprocs@ to indicate where to put the number of processors
#   @command@ to indicate where to put the command to run
#
# only tests with useMPI = 1 will run in parallel
# nprocs is problem dependent and specified in the individual problem
# sections.

MPIcommand = mpiexec -n @nprocs@ @command@
#MPIcommand = mpiexec -host @host@ -n @nprocs@ @command@
#MPIcommand = /usr/lib64/mpich/bin/mpirun -n @nprocs@ @command@
MPIhost = 

extra_tools = fextract

[AMReX]
dir = PELEREGTESTHOME/Repositories/amrex/
branch = development

[source]
dir = PELEREGTESTHOME/Repositories/PeleLM/
branch = development

[extra-IAMR]
dir = PELEREGTESTHOME/Repositories/IAMR/
branch = development

[extra-PelePhysics]
dir = PELEREGTESTHOME/Repositories/PelePhysics/
branch = development

# individual problems follow

[FIAB2] 
buildDir = Exec/RegTests/FlameSheet
inputFile = inputs.2d-regt
probinFile = probin.3d.test
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[FIAB2_restart] 
buildDir = Exec/RegTests/FlameSheet
inputFile = inputs.2d_restarttest
probinFile = probin.3d.test
dim = 2
restartTest = 1
restartFileNum = 12
useMPI = 1
numprocs = 2
useOMP = 1
numthreads = 2
compileTest = 0
doVis = 0

[FIAB3] 
buildDir = Exec/RegTests/FlameSheet
inputFile = inputs.3d-regt
probinFile = probin.3d.test
dim = 3
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 0 
numthreads = 2
compileTest = 0
doVis = 0

[COVO2_MU0] 
buildDir = Exec/RegTests/CoVo
inputFile = inputs.2d-regt_mu0p0
probinFile = probin.2d.regt
dim = 2
restartTest = 0
useMPI = 1
numprocs = 1
useOMP = 0
numthreads = 1
compileTest = 0
doVis = 0

[COVO2_MU0p001] 
buildDir = Exec/RegTests/CoVo
inputFile = inputs.2d-regt_mu0p001
probinFile = probin.2d.regt_mu0p001
dim = 2
restartTest = 0
useMPI = 1
numprocs = 1
useOMP = 0
numthreads = 1
compileTest = 0
doVis = 0

[COVO2_MUEGLiB] 
buildDir = Exec/RegTests/CoVo
addToCompileString = Transport_dir=EGLib
inputFile = inputs.2d-regt_muEGLIB
probinFile = probin.2d.regt_muEGLIB
dim = 2
restartTest = 0
useMPI = 1
numprocs = 1
useOMP = 0
numthreads = 1
compileTest = 0
doVis = 0

[COVO2_MU0_Y] 
buildDir = Exec/RegTests/CoVo
inputFile = inputs.2d-regt_mu0p0_Yd
probinFile = probin.2d.regt-Ydir
dim = 2
restartTest = 0
useMPI = 1
numprocs = 1
useOMP = 0
numthreads = 1
compileTest = 0
doVis = 0

[COVO2_MU0_mY] 
buildDir = Exec/RegTests/CoVo
inputFile = inputs.2d-regt_mu0p0_mYd
probinFile = probin.2d.regt-mYdir
dim = 2
restartTest = 0
useMPI = 1
numprocs = 1
useOMP = 0
numthreads = 1
compileTest = 0
doVis = 0

[FLAMESPEED_X]
buildDir = Exec/RegTests/ControlledInflow
inputFile = inputs.2d_ControlledInlet_Xdir
probinFile = probin.2d_ControlledInlet_Xdir
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 0
numthreads = 1
compileTest = 0
doVis = 0
analysisRoutine = Exec/RegTests/ControlledInflow/Compute_Sl_Xdir.py
analysisMainArgs = tools["fextract"]
analysisOutputImage = FlameSpeedCompa_X.png

[FLAMESPEED_Y]
buildDir = Exec/RegTests/ControlledInflow
inputFile = inputs.2d_ControlledInlet_Ydir
probinFile = probin.2d_ControlledInlet_Ydir
dim = 2
restartTest = 0
useMPI = 1
numprocs = 2
useOMP = 0
numthreads = 1
compileTest = 0
doVis = 0
analysisRoutine = Exec/RegTests/ControlledInflow/Compute_Sl_Ydir.py
analysisMainArgs = tools["fextract"]
analysisOutputImage = FlameSheetCompa_Y.png
